[audio]
# Incoming audio sample rate. If your client sends 48kHz Opus-decoded PCM, set this to 48000.
sample_rate = 16000

# Framing reference (12.5Hz => 80ms per frame)
frame_hz = 12.5

# How many frames to batch into one model request
frames_per_chunk = 4

[qwen]
# Backend:
# - "transformers": local HF inference (end-to-end generate).
# - "team": call sca_run/team_infer.py (plug in teammate pipeline).
backend = "transformers"

# Hugging Face model id or local path
model_id = "Qwen/Qwen3-Omni-30B-A3B-Instruct"

# Common Transformers knobs
# device_map: "auto" to spread across available GPUs; or "cuda:0" for single GPU
device_map = "auto"

# torch_dtype: "auto", "float16", "bfloat16", "float32"
torch_dtype = "auto"

# Optional: "flash_attention_2" if installed; or "eager" / leave empty
attn_implementation = "flash_attention_2"

# Generation length for each request
max_new_tokens = 256

# Ask the backend to return audio (if supported).
return_audio = true

# Sample rate of talker speech output.
# HF docs/examples use 24000 for Qwen3-Omni generated speech.
talker_sample_rate = 24000

# Optional system prompt
system_prompt = "You are a helpful assistant."
